{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce499ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843fb34",
   "metadata": {},
   "source": [
    "personal use script\n",
    "3KmfD3wSp4bA9l-n94v0yQ\n",
    "\n",
    "secret\n",
    "LCj6jFmyJpzAwB0HyXYlRIy6ue1OPQ\n",
    "\n",
    "user\n",
    "Icy-Egg-5982\n",
    "redit_test_\n",
    "\n",
    "\n",
    "pass\n",
    "Aa123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8f163da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='3KmfD3wSp4bA9l-n94v0yQ', client_secret='LCj6jFmyJpzAwB0HyXYlRIy6ue1OPQ', \n",
    "                     user_agent='redit_test_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab25a2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_limit': 2048,\n",
       " 'comment_sort': 'confidence',\n",
       " '_reddit': <praw.reddit.Reddit at 0x278fdf218b0>,\n",
       " 'approved_at_utc': None,\n",
       " 'subreddit': Subreddit(display_name='MachineLearning'),\n",
       " 'selftext': 'Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\\n\\nThread will stay alive until next one so keep posting after the date in the title.\\n\\nThanks to everyone for answering questions in the previous thread!',\n",
       " 'author_fullname': 't2_6l4z3',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': '[D] Simple Questions Thread',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/MachineLearning',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'one',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'top_awarded_type': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_z07o4c',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'upvote_ratio': 1.0,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 14,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'Discussion',\n",
       " 'can_mod_post': False,\n",
       " 'score': 14,\n",
       " 'approved_by': None,\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'author_premium': True,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1668960010.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 6,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'self.MachineLearning',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '<!-- SC_OFF --><div class=\"md\"><p>Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!</p>\\n\\n<p>Thread will stay alive until next one so keep posting after the date in the title.</p>\\n\\n<p>Thanks to everyone for answering questions in the previous thread!</p>\\n</div><!-- SC_ON -->',\n",
       " 'likes': None,\n",
       " 'suggested_sort': 'new',\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_2r3gv',\n",
       " 'author_is_blocked': False,\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': 'z07o4c',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': Redditor(name='AutoModerator'),\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 39,\n",
       " 'send_replies': False,\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/MachineLearning/comments/z07o4c/d_simple_questions_thread/',\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'stickied': True,\n",
       " 'url': 'https://www.reddit.com/r/MachineLearning/comments/z07o4c/d_simple_questions_thread/',\n",
       " 'subreddit_subscribers': 2559941,\n",
       " 'created_utc': 1668960010.0,\n",
       " 'num_crossposts': 0,\n",
       " 'media': None,\n",
       " 'is_video': False,\n",
       " '_fetched': False,\n",
       " '_comments_by_id': {}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 10 hot posts from the MachineLearning subreddit\n",
    "hot_posts = reddit.subreddit('MachineLearning').hot(limit=1)\n",
    "ss = {}\n",
    "for post in hot_posts:\n",
    "    ss = post.__dict__\n",
    "    \n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a222833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Simple Questions Thread\n",
      "https://www.reddit.com/r/MachineLearning/comments/z07o4c/d_simple_questions_thread/\n",
      "39\n",
      "1668960010.0\n",
      "1668960010.0\n",
      "2022-11-20 18:00:10\n",
      "2022-11-20 18:00:10\n",
      "---------------------------\n",
      "[D] AMA: The Stability AI Team\n",
      "https://www.reddit.com/r/MachineLearning/comments/yw6s1i/d_ama_the_stability_ai_team/\n",
      "207\n",
      "1668539839.0\n",
      "1668539839.0\n",
      "2022-11-15 21:17:19\n",
      "2022-11-15 21:17:19\n",
      "---------------------------\n",
      "[D] Schmidhuber: LeCun's \"5 best ideas 2012-22‚Äù are mostly from my lab, and older\n",
      "https://www.reddit.com/r/MachineLearning/comments/z2hr3p/d_schmidhuber_lecuns_5_best_ideas_201222_are/\n",
      "66\n",
      "1669185468.0\n",
      "1669185468.0\n",
      "2022-11-23 08:37:48\n",
      "2022-11-23 08:37:48\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# get 10 hot posts from the MachineLearning subreddit\n",
    "import datetime, time\n",
    "\n",
    "#print datetime.datetime.fromtimestamp(time.time())\n",
    "\n",
    "\n",
    "hot_posts = reddit.subreddit('MachineLearning').hot(limit=3)\n",
    "ss = {}\n",
    "for post in hot_posts:\n",
    "    print( post.title )\n",
    "    print( post.url )\n",
    "    print(post.num_comments)\n",
    "    print(post.created)\n",
    "    print(post.created_utc)\n",
    "    #print(type(post.created))\n",
    "    #print(type(post.created_utc))\n",
    "    print(datetime.datetime.fromtimestamp(post.created))\n",
    "    print(datetime.datetime.fromtimestamp(post.created_utc))\n",
    "    print('---------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4be77fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "praw.models.listing.generator.ListingGenerator"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(hot_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fba7a2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_exhausted',\n",
       " '_extract_sublist',\n",
       " '_is_protocol',\n",
       " '_list_index',\n",
       " '_listing',\n",
       " '_next_batch',\n",
       " '_reddit',\n",
       " '_safely_add_arguments',\n",
       " 'limit',\n",
       " 'params',\n",
       " 'parse',\n",
       " 'url',\n",
       " 'yielded']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hot_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3034bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_exhausted', '_extract_sublist', '_is_protocol', '_list_index', '_listing', '_next_batch', '_reddit', '_safely_add_arguments', 'limit', 'params', 'parse', 'url', 'yielded']\n"
     ]
    }
   ],
   "source": [
    "print(dir(hot_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53a09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9ce0018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subred = reddit.subreddit('learnpython')\n",
    "hot = subred.hot(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03c4baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STR_FIELD',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_chunk',\n",
       " '_comments_by_id',\n",
       " '_fetch',\n",
       " '_fetch_data',\n",
       " '_fetch_info',\n",
       " '_fetched',\n",
       " '_kind',\n",
       " '_reddit',\n",
       " '_reset_attributes',\n",
       " '_safely_add_arguments',\n",
       " '_url_parts',\n",
       " '_vote',\n",
       " 'all_awardings',\n",
       " 'allow_live_comments',\n",
       " 'approved_at_utc',\n",
       " 'approved_by',\n",
       " 'archived',\n",
       " 'author',\n",
       " 'author_flair_background_color',\n",
       " 'author_flair_css_class',\n",
       " 'author_flair_richtext',\n",
       " 'author_flair_template_id',\n",
       " 'author_flair_text',\n",
       " 'author_flair_text_color',\n",
       " 'author_flair_type',\n",
       " 'author_fullname',\n",
       " 'author_is_blocked',\n",
       " 'author_patreon_flair',\n",
       " 'author_premium',\n",
       " 'award',\n",
       " 'awarders',\n",
       " 'banned_at_utc',\n",
       " 'banned_by',\n",
       " 'can_gild',\n",
       " 'can_mod_post',\n",
       " 'category',\n",
       " 'clear_vote',\n",
       " 'clicked',\n",
       " 'comment_limit',\n",
       " 'comment_sort',\n",
       " 'comments',\n",
       " 'content_categories',\n",
       " 'contest_mode',\n",
       " 'created',\n",
       " 'created_utc',\n",
       " 'crosspost',\n",
       " 'delete',\n",
       " 'disable_inbox_replies',\n",
       " 'discussion_type',\n",
       " 'distinguished',\n",
       " 'domain',\n",
       " 'downs',\n",
       " 'downvote',\n",
       " 'duplicates',\n",
       " 'edit',\n",
       " 'edited',\n",
       " 'enable_inbox_replies',\n",
       " 'flair',\n",
       " 'fullname',\n",
       " 'gild',\n",
       " 'gilded',\n",
       " 'gildings',\n",
       " 'hidden',\n",
       " 'hide',\n",
       " 'hide_score',\n",
       " 'id',\n",
       " 'id_from_url',\n",
       " 'is_created_from_ads_ui',\n",
       " 'is_crosspostable',\n",
       " 'is_meta',\n",
       " 'is_original_content',\n",
       " 'is_reddit_media_domain',\n",
       " 'is_robot_indexable',\n",
       " 'is_self',\n",
       " 'is_video',\n",
       " 'likes',\n",
       " 'link_flair_background_color',\n",
       " 'link_flair_css_class',\n",
       " 'link_flair_richtext',\n",
       " 'link_flair_text',\n",
       " 'link_flair_text_color',\n",
       " 'link_flair_type',\n",
       " 'locked',\n",
       " 'mark_visited',\n",
       " 'media',\n",
       " 'media_embed',\n",
       " 'media_only',\n",
       " 'mod',\n",
       " 'mod_note',\n",
       " 'mod_reason_by',\n",
       " 'mod_reason_title',\n",
       " 'mod_reports',\n",
       " 'name',\n",
       " 'no_follow',\n",
       " 'num_comments',\n",
       " 'num_crossposts',\n",
       " 'num_reports',\n",
       " 'over_18',\n",
       " 'parent_whitelist_status',\n",
       " 'parse',\n",
       " 'permalink',\n",
       " 'pinned',\n",
       " 'pwls',\n",
       " 'quarantine',\n",
       " 'removal_reason',\n",
       " 'removed_by',\n",
       " 'removed_by_category',\n",
       " 'reply',\n",
       " 'report',\n",
       " 'report_reasons',\n",
       " 'save',\n",
       " 'saved',\n",
       " 'score',\n",
       " 'secure_media',\n",
       " 'secure_media_embed',\n",
       " 'selftext',\n",
       " 'selftext_html',\n",
       " 'send_replies',\n",
       " 'shortlink',\n",
       " 'spoiler',\n",
       " 'stickied',\n",
       " 'subreddit',\n",
       " 'subreddit_id',\n",
       " 'subreddit_name_prefixed',\n",
       " 'subreddit_subscribers',\n",
       " 'subreddit_type',\n",
       " 'suggested_sort',\n",
       " 'thumbnail',\n",
       " 'title',\n",
       " 'top_awarded_type',\n",
       " 'total_awards_received',\n",
       " 'treatment_tags',\n",
       " 'unhide',\n",
       " 'unsave',\n",
       " 'ups',\n",
       " 'upvote',\n",
       " 'upvote_ratio',\n",
       " 'url',\n",
       " 'user_reports',\n",
       " 'view_count',\n",
       " 'visited',\n",
       " 'whitelist_status',\n",
       " 'wls']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(hot)\n",
    "q = list(dir(x))\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6e5b0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "print(len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1c6c27ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STR_FIELD', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunk', '_comments_by_id', '_fetch', '_fetch_data', '_fetch_info', '_fetched', '_kind', '_reddit', '_reset_attributes', '_safely_add_arguments', '_url_parts', '_vote', 'all_awardings', 'allow_live_comments', 'approved_at_utc', 'approved_by', 'archived', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'award', 'awarders', 'banned_at_utc', 'banned_by', 'can_gild', 'can_mod_post', 'category', 'clear_vote', 'clicked', 'comment_limit', 'comment_sort', 'comments', 'content_categories', 'contest_mode', 'created', 'created_utc', 'crosspost', 'delete', 'disable_inbox_replies', 'discussion_type', 'distinguished', 'domain', 'downs', 'downvote', 'duplicates', 'edit', 'edited', 'enable_inbox_replies', 'flair', 'fullname', 'gild', 'gilded', 'gildings', 'hidden', 'hide', 'hide_score', 'id', 'id_from_url', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'likes', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'mark_visited', 'media', 'media_embed', 'media_only', 'mod', 'mod_note', 'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_comments', 'num_crossposts', 'num_reports', 'over_18', 'parent_whitelist_status', 'parse', 'permalink', 'pinned', 'pwls', 'quarantine', 'removal_reason', 'removed_by', 'removed_by_category', 'reply', 'report', 'report_reasons', 'save', 'saved', 'score', 'secure_media', 'secure_media_embed', 'selftext', 'selftext_html', 'send_replies', 'shortlink', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'title', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unhide', 'unsave', 'ups', 'upvote', 'upvote_ratio', 'url', 'user_reports', 'view_count', 'visited', 'whitelist_status', 'wls']\n"
     ]
    }
   ],
   "source": [
    "print(dir(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fba0fa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_limit': 2048,\n",
       " 'comment_sort': 'confidence',\n",
       " '_reddit': <praw.reddit.Reddit at 0x278fdf218b0>,\n",
       " 'approved_at_utc': None,\n",
       " 'subreddit': Subreddit(display_name='MachineLearning'),\n",
       " 'selftext': \"Demo: https://huggingface.co/spaces/fxmarty/bettertransformer-demo\\n\\nHi everyone,\\n\\nIn the latest [PyTorch stable release 1.13](https://pytorch.org/blog/PyTorch-1.13-release/), the BetterTransformer feature was marked as stable! It is a free-lunch optimization to gain x1.25 - x4 speedups on the inference of Transformer-based models. Notably, it leverages kernels fusion and the sparsity due to the padding tokens.\\n\\nIn order to support BetterTransformer with the canonical Transformer models from [Transformers library](https://github.com/huggingface/transformers), an integration was done with the open-source library [Optimum](https://github.com/huggingface/optimum) as a **one-liner**:\\n\\n    from optimum.bettertransformer import BetterTransformer\\n    \\n    model = BetterTransformer.transform(model)\\n\\nI did a Space to showcase a bit the speedups we can have in a **end-to-end** case with [TorchServe](https://pytorch.org/serve/) to deploy the model on a cloud instance (AWS EC2 g4dn, using one T4 GPU): https://huggingface.co/spaces/fxmarty/bettertransformer-demo\\n\\nThe idea of the Space is to show two use case scenarios:\\n\\n* One-shot input (batch size = 1), where we would like to optimize for latency (this not where BetterTransformer is the best, it has better perfs with larger batch size and some padding)\\n* Heavy workload, with many inference requests, where we would like to optimize for throughput (samples/s)\\n\\nThe TL;DR is:\\n\\n* You can reduce your latency between x1.25 - x4 depending on your hardware (even better results on Ampere, CPU can be leveraged as well), batch size, sequence length, padding ratio.\\n* TorchServe is great for out-of-the-box deployment, although it requires some configuration. Achieving maximum throughput is not super straightforward, and I am convinced we could have even better results than on the demo by tuning TorchServe or using other serving tools.\\n\\nFor more precise benchmarks, check out as well the [blog post on PyTorch's Medium](https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2) about the integration, and the [Optimum documentation](https://huggingface.co/docs/optimum/bettertransformer/overview) for more details on the implementation!\\n\\nIf you would like to deploy a model powered by BetterTransformer super straightforwardly, I would recommend trying the [HF's Inference Endpoints](https://huggingface.co/docs/inference-endpoints/index) with a [custom handler](https://huggingface.co/docs/inference-endpoints/guides/custom_handler). In the future I'll try Nvidia Triton as well, although I hear it can be a bit more involved to configure compared to TorchServe.\\n\\nKudos to Hamid Shojanazeri from PyTorch for his great advice on the demo!\",\n",
       " 'author_fullname': 't2_bnok6yyj',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': '[P] BetterTransformer: PyTorch-native free-lunch speedups for Transformer-based models',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/MachineLearning',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'four',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'top_awarded_type': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_z1titt',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'upvote_ratio': 0.98,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 110,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'Project',\n",
       " 'can_mod_post': False,\n",
       " 'score': 110,\n",
       " 'approved_by': None,\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'author_premium': False,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': 1669124434.0,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {},\n",
       " 'post_hint': 'self',\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1669123483.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 6,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'self.MachineLearning',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '<!-- SC_OFF --><div class=\"md\"><p>Demo: <a href=\"https://huggingface.co/spaces/fxmarty/bettertransformer-demo\">https://huggingface.co/spaces/fxmarty/bettertransformer-demo</a></p>\\n\\n<p>Hi everyone,</p>\\n\\n<p>In the latest <a href=\"https://pytorch.org/blog/PyTorch-1.13-release/\">PyTorch stable release 1.13</a>, the BetterTransformer feature was marked as stable! It is a free-lunch optimization to gain x1.25 - x4 speedups on the inference of Transformer-based models. Notably, it leverages kernels fusion and the sparsity due to the padding tokens.</p>\\n\\n<p>In order to support BetterTransformer with the canonical Transformer models from <a href=\"https://github.com/huggingface/transformers\">Transformers library</a>, an integration was done with the open-source library <a href=\"https://github.com/huggingface/optimum\">Optimum</a> as a <strong>one-liner</strong>:</p>\\n\\n<pre><code>from optimum.bettertransformer import BetterTransformer\\n\\nmodel = BetterTransformer.transform(model)\\n</code></pre>\\n\\n<p>I did a Space to showcase a bit the speedups we can have in a <strong>end-to-end</strong> case with <a href=\"https://pytorch.org/serve/\">TorchServe</a> to deploy the model on a cloud instance (AWS EC2 g4dn, using one T4 GPU): <a href=\"https://huggingface.co/spaces/fxmarty/bettertransformer-demo\">https://huggingface.co/spaces/fxmarty/bettertransformer-demo</a></p>\\n\\n<p>The idea of the Space is to show two use case scenarios:</p>\\n\\n<ul>\\n<li>One-shot input (batch size = 1), where we would like to optimize for latency (this not where BetterTransformer is the best, it has better perfs with larger batch size and some padding)</li>\\n<li>Heavy workload, with many inference requests, where we would like to optimize for throughput (samples/s)</li>\\n</ul>\\n\\n<p>The TL;DR is:</p>\\n\\n<ul>\\n<li>You can reduce your latency between x1.25 - x4 depending on your hardware (even better results on Ampere, CPU can be leveraged as well), batch size, sequence length, padding ratio.</li>\\n<li>TorchServe is great for out-of-the-box deployment, although it requires some configuration. Achieving maximum throughput is not super straightforward, and I am convinced we could have even better results than on the demo by tuning TorchServe or using other serving tools.</li>\\n</ul>\\n\\n<p>For more precise benchmarks, check out as well the <a href=\"https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2\">blog post on PyTorch&#39;s Medium</a> about the integration, and the <a href=\"https://huggingface.co/docs/optimum/bettertransformer/overview\">Optimum documentation</a> for more details on the implementation!</p>\\n\\n<p>If you would like to deploy a model powered by BetterTransformer super straightforwardly, I would recommend trying the <a href=\"https://huggingface.co/docs/inference-endpoints/index\">HF&#39;s Inference Endpoints</a> with a <a href=\"https://huggingface.co/docs/inference-endpoints/guides/custom_handler\">custom handler</a>. In the future I&#39;ll try Nvidia Triton as well, although I hear it can be a bit more involved to configure compared to TorchServe.</p>\\n\\n<p>Kudos to Hamid Shojanazeri from PyTorch for his great advice on the demo!</p>\\n</div><!-- SC_ON -->',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?auto=webp&s=73b6c2e57f003886c59690c30b7b7d435d36a69f',\n",
       "     'width': 1200,\n",
       "     'height': 648},\n",
       "    'resolutions': [{'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=108&crop=smart&auto=webp&s=84f519f17a4b1fbcb761461237e896c05350434f',\n",
       "      'width': 108,\n",
       "      'height': 58},\n",
       "     {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=216&crop=smart&auto=webp&s=d1df53cf7e888a17ab46444a8a508c24f4c7288c',\n",
       "      'width': 216,\n",
       "      'height': 116},\n",
       "     {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=320&crop=smart&auto=webp&s=0c55659f5afa70c643197866274fca4591592f33',\n",
       "      'width': 320,\n",
       "      'height': 172},\n",
       "     {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=640&crop=smart&auto=webp&s=9075e539775e61c2926c1fcc0effb24f31461855',\n",
       "      'width': 640,\n",
       "      'height': 345},\n",
       "     {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=960&crop=smart&auto=webp&s=7d43d138e1b6f522b9b98c9d28ebb39f0f33fd40',\n",
       "      'width': 960,\n",
       "      'height': 518},\n",
       "     {'url': 'https://external-preview.redd.it/qo_Wi4_wXCkVGFeBdAng_umgI_crr41TjsBnwsumkLk.jpg?width=1080&crop=smart&auto=webp&s=79bf5667c469f47ae3531514b6efe6192e0ed2df',\n",
       "      'width': 1080,\n",
       "      'height': 583}],\n",
       "    'variants': {},\n",
       "    'id': 'zdyxs-yCfgzciKN-PlT39z7duRnSY90kaOaHEmpdJMY'}],\n",
       "  'enabled': False},\n",
       " 'all_awardings': [],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_2r3gv',\n",
       " 'author_is_blocked': False,\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': 'z1titt',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': Redditor(name='fxmarty'),\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 23,\n",
       " 'send_replies': True,\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/MachineLearning/comments/z1titt/p_bettertransformer_pytorchnative_freelunch/',\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'stickied': False,\n",
       " 'url': 'https://www.reddit.com/r/MachineLearning/comments/z1titt/p_bettertransformer_pytorchnative_freelunch/',\n",
       " 'subreddit_subscribers': 2559940,\n",
       " 'created_utc': 1669123483.0,\n",
       " 'num_crossposts': 0,\n",
       " 'media': None,\n",
       " 'is_video': False,\n",
       " '_fetched': False,\n",
       " '_comments_by_id': {}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subred = reddit.subreddit('MachineLearning')\n",
    "hot = subred.hot(limit=10)\n",
    "\n",
    "ss = {}\n",
    "for post in hot:\n",
    "    ss = post.__dict__\n",
    "    \n",
    "\n",
    "ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56c084d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "subred = reddit.subreddit('MachineLearning')\n",
    "hot = subred.hot(limit=10)\n",
    "\n",
    "#rint(type(hot))\n",
    "ss = {}\n",
    "#s = pd.DataFrame(hot)\n",
    "for post in hot:\n",
    "    ss = post.__dict__\n",
    "\n",
    "\n",
    "print(type(ss))\n",
    "#gs_df = pd.DataFrame.from_dict(ss)\n",
    "#gs_df\n",
    "ss\n",
    "print(type(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1b9ef3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n",
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n",
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACTIVE\\AppData\\Local\\Temp\\ipykernel_12660\\133257224.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(post.__dict__, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'comment_limit': 2048,\n",
       " 'comment_sort': 'confidence',\n",
       " '_reddit': <praw.reddit.Reddit at 0x278fdf218b0>,\n",
       " 'approved_at_utc': None,\n",
       " 'subreddit': Subreddit(display_name='MachineLearning'),\n",
       " 'selftext': \"Are there good (job/career) networking opportunities at NeurIPS if you're not presenting a paper? Or is it just a chaotic crowd of thousands of people? I'm trying to decide whether it makes sense to attend (I'm actively searching for geographically-constrained or remote-only job opportunities) or if instead I should look for a smaller and more personal event.\\n\\n*(P.S. I noted an* [*earlier post*](https://www.reddit.com/r/MachineLearning/comments/xshkbf/d_is_it_worth_attending_neurips_2022/) *asking if it was worth attending, however I felt it didn't address the job search question directly)*\",\n",
       " 'author_fullname': 't2_u3slm85y',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': '[D] Attend NeurIPS for a job search vs. a smaller event',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/MachineLearning',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'one',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'top_awarded_type': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_z2akd6',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'upvote_ratio': 0.86,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 15,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'Discussion',\n",
       " 'can_mod_post': False,\n",
       " 'score': 15,\n",
       " 'approved_by': None,\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'author_premium': False,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1669164359.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 6,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'self.MachineLearning',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '<!-- SC_OFF --><div class=\"md\"><p>Are there good (job/career) networking opportunities at NeurIPS if you&#39;re not presenting a paper? Or is it just a chaotic crowd of thousands of people? I&#39;m trying to decide whether it makes sense to attend (I&#39;m actively searching for geographically-constrained or remote-only job opportunities) or if instead I should look for a smaller and more personal event.</p>\\n\\n<p><em>(P.S. I noted an</em> <a href=\"https://www.reddit.com/r/MachineLearning/comments/xshkbf/d_is_it_worth_attending_neurips_2022/\"><em>earlier post</em></a> <em>asking if it was worth attending, however I felt it didn&#39;t address the job search question directly)</em></p>\\n</div><!-- SC_ON -->',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_2r3gv',\n",
       " 'author_is_blocked': False,\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': 'z2akd6',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': Redditor(name='No-Shelter206'),\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 3,\n",
       " 'send_replies': True,\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/MachineLearning/comments/z2akd6/d_attend_neurips_for_a_job_search_vs_a_smaller/',\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'stickied': False,\n",
       " 'url': 'https://www.reddit.com/r/MachineLearning/comments/z2akd6/d_attend_neurips_for_a_job_search_vs_a_smaller/',\n",
       " 'subreddit_subscribers': 2559943,\n",
       " 'created_utc': 1669164359.0,\n",
       " 'num_crossposts': 0,\n",
       " 'media': None,\n",
       " 'is_video': False,\n",
       " '_fetched': False,\n",
       " '_comments_by_id': {}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_posts = reddit.subreddit('MachineLearning').hot(limit=10)\n",
    "\n",
    "ss = {}\n",
    "output = pd.DataFrame()\n",
    "for post in hot_posts:\n",
    "    ss = post.__dict__\n",
    "    print(type(post.__dict__))\n",
    "    #print(post.__dict__)\n",
    "    print('++++++++++++++++++++++++++++++++++')\n",
    "    output = output.append(post.__dict__, ignore_index=True)\n",
    "    \n",
    "#output.append(ss, ignore_index=True)\n",
    "ss\n",
    "#output\n",
    "#songs_df.to_excel(\"songs_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1ba31f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_limit</th>\n",
       "      <th>comment_sort</th>\n",
       "      <th>_reddit</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>_fetched</th>\n",
       "      <th>_comments_by_id</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>media_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.668960e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Hi all,\\n\\nWe are the Stability AI team suppor...</td>\n",
       "      <td>t2_ubvecxhp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.668540e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Twitter link: https://twitter.com/SchmidhuberA...</td>\n",
       "      <td>t2_5dt1knqh</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669185e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>self</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>We made a background removal tool named as **t...</td>\n",
       "      <td>t2_3frnr0nu</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669204e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'iaz5tyzhuo1a1': {'status': 'valid', 'e': 'Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>I have uploaded two repositories on github - t...</td>\n",
       "      <td>t2_d0vyg</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669185e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>self</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Paper: [https://www.science.org/doi/10.1126/sc...</td>\n",
       "      <td>t2_341curhr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669137e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sf8igrddaj1a1': {'status': 'valid', 'e': 'Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Website: [https://minedojo.org](https://minedo...</td>\n",
       "      <td>t2_9l187vq4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669242e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'4ufw0ygn0s1a1': {'status': 'valid', 'e': 'Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>I see a lot of image models (ImageNet, ResNet,...</td>\n",
       "      <td>t2_kg0l0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669237e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>For an ML project I have at work, I've been co...</td>\n",
       "      <td>t2_qjoe4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669163e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2048</td>\n",
       "      <td>confidence</td>\n",
       "      <td>&lt;praw.reddit.Reddit object at 0x00000278FDF218B0&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Are there good (job/career) networking opportu...</td>\n",
       "      <td>t2_u3slm85y</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2559943</td>\n",
       "      <td>1.669164e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_limit comment_sort  \\\n",
       "0           2048   confidence   \n",
       "1           2048   confidence   \n",
       "2           2048   confidence   \n",
       "3           2048   confidence   \n",
       "4           2048   confidence   \n",
       "5           2048   confidence   \n",
       "6           2048   confidence   \n",
       "7           2048   confidence   \n",
       "8           2048   confidence   \n",
       "9           2048   confidence   \n",
       "\n",
       "                                             _reddit approved_at_utc  \\\n",
       "0  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "1  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "2  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "3  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "4  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "5  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "6  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "7  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "8  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "9  <praw.reddit.Reddit object at 0x00000278FDF218B0>            None   \n",
       "\n",
       "         subreddit                                           selftext  \\\n",
       "0  MachineLearning  Please post your questions here instead of cre...   \n",
       "1  MachineLearning  Hi all,\\n\\nWe are the Stability AI team suppor...   \n",
       "2  MachineLearning  Twitter link: https://twitter.com/SchmidhuberA...   \n",
       "3  MachineLearning  We made a background removal tool named as **t...   \n",
       "4  MachineLearning  I have uploaded two repositories on github - t...   \n",
       "5  MachineLearning  Paper: [https://www.science.org/doi/10.1126/sc...   \n",
       "6  MachineLearning  Website: [https://minedojo.org](https://minedo...   \n",
       "7  MachineLearning  I see a lot of image models (ImageNet, ResNet,...   \n",
       "8  MachineLearning  For an ML project I have at work, I've been co...   \n",
       "9  MachineLearning  Are there good (job/career) networking opportu...   \n",
       "\n",
       "  author_fullname  saved mod_reason_title  gilded  ...  subreddit_subscribers  \\\n",
       "0        t2_6l4z3  False             None       0  ...                2559943   \n",
       "1     t2_ubvecxhp  False             None       0  ...                2559943   \n",
       "2     t2_5dt1knqh  False             None       0  ...                2559943   \n",
       "3     t2_3frnr0nu  False             None       0  ...                2559943   \n",
       "4        t2_d0vyg  False             None       0  ...                2559943   \n",
       "5     t2_341curhr  False             None       0  ...                2559943   \n",
       "6     t2_9l187vq4  False             None       0  ...                2559943   \n",
       "7        t2_kg0l0  False             None       0  ...                2559943   \n",
       "8        t2_qjoe4  False             None       0  ...                2559943   \n",
       "9     t2_u3slm85y  False             None       0  ...                2559943   \n",
       "\n",
       "    created_utc num_crossposts media  is_video  _fetched _comments_by_id  \\\n",
       "0  1.668960e+09              0  None     False     False              {}   \n",
       "1  1.668540e+09              1  None     False     False              {}   \n",
       "2  1.669185e+09              0  None     False     False              {}   \n",
       "3  1.669204e+09              0  None     False     False              {}   \n",
       "4  1.669185e+09              0  None     False     False              {}   \n",
       "5  1.669137e+09              2  None     False     False              {}   \n",
       "6  1.669242e+09              0  None     False     False              {}   \n",
       "7  1.669237e+09              0  None     False     False              {}   \n",
       "8  1.669163e+09              0  None     False     False              {}   \n",
       "9  1.669164e+09              0  None     False     False              {}   \n",
       "\n",
       "   post_hint                                            preview  \\\n",
       "0        NaN                                                NaN   \n",
       "1        NaN                                                NaN   \n",
       "2       self  {'images': [{'source': {'url': 'https://extern...   \n",
       "3        NaN                                                NaN   \n",
       "4       self  {'images': [{'source': {'url': 'https://extern...   \n",
       "5        NaN                                                NaN   \n",
       "6        NaN                                                NaN   \n",
       "7        NaN                                                NaN   \n",
       "8        NaN                                                NaN   \n",
       "9        NaN                                                NaN   \n",
       "\n",
       "                                      media_metadata  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  {'iaz5tyzhuo1a1': {'status': 'valid', 'e': 'Im...  \n",
       "4                                                NaN  \n",
       "5  {'sf8igrddaj1a1': {'status': 'valid', 'e': 'Im...  \n",
       "6  {'4ufw0ygn0s1a1': {'status': 'valid', 'e': 'Im...  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "\n",
       "[10 rows x 114 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "db81bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel(\"songs_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d72e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8d786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
